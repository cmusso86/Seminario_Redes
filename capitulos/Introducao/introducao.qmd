---
title: "Importância de Variáveis"
---

## What to expect 

- Introduction 
  - Interpretability of models
- Techniques for model interpretation
- Hands-on example:
  - Shap
  - Lime
  - Causal Inference
- Conclusions

# Introduction


## Introduction: Importance of variables

- Interpretability in a Data Driven World

- Machine learning model is faster and cheaper to train in comparison to humans.

- If you focus only on performance, you will automatically get more and more opaque models. 
  -  winning models are ensembles of models or boosted trees/deep neural networks.


## Introduction: Importance of variables

- It is also essential to verify if the accuracy does not result from the exploitation of artifacts.

- Key ingredient of a robust validation procedure.

- Important in applications such in health ans social sciences and where accountability is important. 

- Tool for exploration and analysis in the sciences,  to extract new insights from complex physical, chemical, or biological systems.

## Introduction: The classic approach

- Models inherently interpretable: linear regression, logistic regression, decision tree...
   - Coefficients: rates, odds ratio...
   
- Lower predictive performance in comparison to other machine learning models.

- However, insights are hidden in increasingly complex models. 


## Introduction: Interpreting DNNs

-  Interpreting deep networks remains a young and emerging field of research. 
  - Numerous coexisting approaches.
  - We will present some possible techniques. 
  - Focus on supervised learning.

- [Interpretable Machine Learning, Christoph Molnar](https://christophm.github.io/interpretable-ml-book/)
- [Montavon et al. (2018)](https://www.sciencedirect.com/science/article/pii/S1051200417302385?via%3Dihub)


